# Job Matcher AI - Your Smart AI-Powered Job Search Assistant

ğŸ” Finding the right job shouldn't feel like searching for a needle in a haystack. **Job Matcher AI** is an AI-powered job search assistant that leverages **Retrieval-Augmented Generation (RAG)**, **vector search**, **LLM-driven query refinement**, and **intelligent reranking** to deliver highly relevant job recommendations.

---


## ğŸ“– Table of Contents

- [ğŸ’¡ Overview](#overview)
- [âš™ï¸ How to Use the Job Matcher AI App](#how-to-use-the-job-matcher-ai-app)
- [ğŸ› ï¸ System Architecture](#system-architecture)
- [ğŸŒ Data Collection and Preprocessing](#data-collection-and-preprocessing)
  - [ğŸ“¡ Web Scraping - Collecting Job Listings](#web-scraping---collecting-job-listings)
  - [ğŸ“Š Data Preprocessing and Vector Database Setup](#data-preprocessing-and-vector-database-setup)
- [ğŸ”® Future Improvements](#notes--future-improvements)
- [ğŸ“œ License](#license)

---

## Overview

**Job Matcher AI** uses state-of-the-art AI models to help users find the most relevant job listings by refining user queries, searching vector databases, and ranking results intelligently. 

It features:

âœ… **Real-time job retrieval** using a combination of LLMs and vector search.

âœ… **AI-powered query refinement** for better search accuracy.

âœ… **Semantic Graph Chunking** for improved text segmentation.

âœ… **Reranking with cross-encoders** to ensure top-quality results.

âœ… **Interactive UI** powered by **Streamlit**.

---

## How to Use the Job Matcher AI App

### ğŸ“¦ Installation & Requirements
Ensure all dependencies are installed using the `requirements.txt` file.

Run this command on your IDE terminal:
```bash
pip install -r requirements.txt
```

### ğŸ¯ Running the Job Matcher AI App
#### **ğŸ“‚ Files Needed:**
- `main_app_code.py` - The core backend logic that retrieves, ranks, and refines job matches.
- `streamlit_app.py` - The Streamlit UI to interact with the system.

#### **â–¶ï¸ Setup Instructions:**
1. Ensure `main_app_code.py` and `streamlit_app.py` are in the same directory.
2. Obtain API keys for **Pinecone** and **Cohere**, and store them in a `.env` file (not included in this repository).
3. Open a terminal, navigate to the app directory, and run:
   ```bash
   streamlit run streamlit_app.py
   ```
4. The app will launch on a local host.
5. â³ **Expect an initial load time of 20-30 seconds.**

---

## System Architecture

ğŸ–¼ï¸ *(Insert a diagram here showcasing the entire RAG pipeline, including query refinement, retrieval, reranking, and response generation.)*

---

## ğŸŒ Data Collection and Preprocessing (For Developers and Enthusiasts)

### ğŸ“¡ Web Scraping - Collecting Job Listings
#### **ğŸ“ Files:**
- `indeed_scraper.py` - The job listing scraper.
- `run_scraper.py` - Runs the scraper in a loop every few hours.

#### **ğŸ”‘ Requirements:**
- Requires **Bright Data** credentials (**USERNAME** and **PASSWORD**) stored in the `.env` file.
- The scraper runs automatically when `run_scraper.py` is executed.

### ğŸ“Š Data Preprocessing and Vector Database Setup
#### **ğŸ” Files:**
- `analys_preprocess_and_vectordb.ipynb` - Jupyter Notebook for:
  - ğŸ› ï¸ **Data cleaning** and **preprocessing** with **Apache Spark**.
  - ğŸ”¡ **Text normalization** and **feature engineering** (e.g., adding education level, filling missing values).
  - ğŸ§© **Chunking job descriptions** using **Semantic Graph Chunking**.
  - ğŸ“¦ **Storing job listings in Pinecone Vector DB**.
- `semantic_graph_chunker.py` - Standalone script for **Semantic Graph Chunking**.

#### **âš™ï¸ How to Run:**
- Best run on **Databricks** due to large-scale data processing.
- ğŸ“‚ Upload the **parquet dataset** (`combined_data_80k.parquet` or `combined_data_190k.parquet`) to Databricks.
- Set the **data directory, Pinecone API key, and index name** in the first cell of the notebook.
- â³ **Running this step takes time, but it is not necessary to use the app**, as the data is already stored in Pinecone.

---

## ğŸ”® Notes & Future Improvements
- ğŸ”‘ The `.env` file containing API keys is **not included** in this repository and must be obtained separately.
- ğŸ“Œ The preprocessing step is **not required** to run the app, as the job data is already indexed.
- âš¡ Future work will focus on **optimizing speed**, **improving prompt engineering**, and **scaling the system** to integrate with real-time job boards.

---

## ğŸ“œ License
This project is intended for educational and research purposes.

ğŸ’¬ For any inquiries, please open an issue or reach out to the contributors.

